{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from neural_network import NeuralNetworkModel, ChessDataset, ChessEvaluationNeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/chess_data.csv\")\n",
    "\n",
    "df = df[~df['Evaluation'].str.contains('#', na=False)]\n",
    "X = df['FEN'].apply(NeuralNetworkModel.fen_to_feature_array).tolist()\n",
    "X = np.array(X, dtype=np.float32)\n",
    "y = df['Evaluation'].apply(lambda x: float(x)).astype(np.float32).values.reshape(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "train_dataset = ChessDataset(X_train, y_train)\n",
    "test_dataset = ChessDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 367420.5618\n",
      "Epoch 2, Loss: 345893.3333\n",
      "Epoch 3, Loss: 326947.2408\n",
      "Epoch 4, Loss: 310707.1357\n",
      "Epoch 5, Loss: 299233.4750\n",
      "Epoch 6, Loss: 290878.1974\n",
      "Epoch 7, Loss: 283247.3704\n",
      "Epoch 8, Loss: 273944.6698\n",
      "Epoch 9, Loss: 266409.1027\n",
      "Epoch 10, Loss: 262375.6890\n",
      "Epoch 11, Loss: 254384.7618\n",
      "Epoch 12, Loss: 248943.4825\n",
      "Epoch 13, Loss: 242930.0842\n",
      "Epoch 14, Loss: 236099.4430\n",
      "Epoch 15, Loss: 233670.7819\n",
      "Epoch 16, Loss: 226614.2765\n",
      "Epoch 17, Loss: 221269.2277\n",
      "Epoch 18, Loss: 216416.2884\n",
      "Epoch 19, Loss: 212447.2408\n",
      "Epoch 20, Loss: 207124.8049\n",
      "Epoch 21, Loss: 206207.6170\n",
      "Epoch 22, Loss: 201129.4538\n",
      "Epoch 23, Loss: 192556.4602\n",
      "Epoch 24, Loss: 191095.7385\n",
      "Epoch 25, Loss: 186954.2691\n",
      "Epoch 26, Loss: 184218.5067\n",
      "Epoch 27, Loss: 183174.3129\n",
      "Epoch 28, Loss: 175478.5289\n",
      "Epoch 29, Loss: 174582.9381\n",
      "Epoch 30, Loss: 168840.6397\n",
      "Epoch 31, Loss: 168121.1887\n",
      "Epoch 32, Loss: 163207.7072\n",
      "Epoch 33, Loss: 161149.1781\n",
      "Epoch 34, Loss: 156530.6353\n",
      "Epoch 35, Loss: 155449.5973\n",
      "Epoch 36, Loss: 151474.9002\n",
      "Epoch 37, Loss: 146561.1346\n",
      "Epoch 38, Loss: 148524.0870\n",
      "Epoch 39, Loss: 143040.6436\n",
      "Epoch 40, Loss: 141195.3582\n",
      "Epoch 41, Loss: 139316.1192\n",
      "Epoch 42, Loss: 137404.3040\n",
      "Epoch 43, Loss: 133755.2311\n",
      "Epoch 44, Loss: 132015.0277\n",
      "Epoch 45, Loss: 131968.5846\n",
      "Epoch 46, Loss: 128451.5996\n",
      "Epoch 47, Loss: 124925.9773\n",
      "Epoch 48, Loss: 126060.6701\n",
      "Epoch 49, Loss: 122412.4719\n",
      "Epoch 50, Loss: 118472.3813\n",
      "Epoch 51, Loss: 119790.5026\n",
      "Epoch 52, Loss: 117108.7856\n",
      "Epoch 53, Loss: 114455.0105\n",
      "Epoch 54, Loss: 115674.9669\n",
      "Epoch 55, Loss: 113626.6043\n",
      "Epoch 56, Loss: 110639.1985\n",
      "Epoch 57, Loss: 108717.7473\n",
      "Epoch 58, Loss: 110122.2853\n",
      "Epoch 59, Loss: 106061.0701\n",
      "Epoch 60, Loss: 106562.4061\n",
      "Epoch 61, Loss: 105164.4733\n",
      "Epoch 62, Loss: 100489.4106\n",
      "Epoch 63, Loss: 101592.0769\n",
      "Epoch 64, Loss: 99350.3839\n",
      "Epoch 65, Loss: 98884.3299\n",
      "Epoch 66, Loss: 96507.4429\n",
      "Epoch 67, Loss: 97273.6262\n",
      "Epoch 68, Loss: 92768.3432\n",
      "Epoch 69, Loss: 95172.3199\n",
      "Epoch 70, Loss: 93526.5212\n",
      "Epoch 71, Loss: 93148.5032\n",
      "Epoch 72, Loss: 90251.7016\n",
      "Epoch 73, Loss: 90042.2064\n",
      "Epoch 74, Loss: 91384.3303\n",
      "Epoch 75, Loss: 89696.9381\n",
      "Epoch 76, Loss: 85454.9802\n",
      "Epoch 77, Loss: 88186.2412\n",
      "Epoch 78, Loss: 87073.3777\n",
      "Epoch 79, Loss: 81726.9008\n",
      "Epoch 80, Loss: 83439.9691\n",
      "Epoch 81, Loss: 82896.8202\n",
      "Epoch 82, Loss: 82907.1403\n",
      "Epoch 83, Loss: 82374.1805\n",
      "Epoch 84, Loss: 80300.6303\n",
      "Epoch 85, Loss: 79564.9959\n",
      "Epoch 86, Loss: 78779.7493\n",
      "Epoch 87, Loss: 79156.7812\n",
      "Epoch 88, Loss: 78016.5208\n",
      "Epoch 89, Loss: 75093.8134\n",
      "Epoch 90, Loss: 77331.5136\n",
      "Epoch 91, Loss: 75124.5195\n",
      "Epoch 92, Loss: 73786.8777\n",
      "Epoch 93, Loss: 74221.9525\n",
      "Epoch 94, Loss: 74635.7145\n",
      "Epoch 95, Loss: 71971.5125\n",
      "Epoch 96, Loss: 71048.2909\n",
      "Epoch 97, Loss: 72042.4862\n",
      "Epoch 98, Loss: 73492.7482\n",
      "Epoch 99, Loss: 68826.0331\n",
      "Epoch 100, Loss: 69882.5598\n"
     ]
    }
   ],
   "source": [
    "model = ChessEvaluationNeuralNetwork(input_size=X.shape[1])\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test RMSE: 488.8287\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "rmse_error = np.sqrt(avg_test_loss)\n",
    "print(f\"\\nTest RMSE: {rmse_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'neural_network.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
