{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from neural_network import NeuralNetworkModel, ChessDataset, ChessEvaluationNeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_to_output(eval: str):\n",
    "    if eval.startswith('#+'):\n",
    "        return 10000.0\n",
    "    elif eval.startswith('#-'):\n",
    "        return -10000.0\n",
    "    else:\n",
    "        return float(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/chess_data.csv\")\n",
    "\n",
    "X = df['FEN'].apply(NeuralNetworkModel.fen_to_feature_array).tolist()\n",
    "X = np.array(X, dtype=np.float32)\n",
    "y = df['Evaluation'].apply(eval_to_output).astype(np.float32).values.reshape(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "train_dataset = ChessDataset(X_train, y_train)\n",
    "test_dataset = ChessDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 935961.3182\n",
      "Epoch 2, Loss: 871773.0489\n",
      "Epoch 3, Loss: 819744.6439\n",
      "Epoch 4, Loss: 782289.5968\n",
      "Epoch 5, Loss: 754557.6215\n",
      "Epoch 6, Loss: 730450.8218\n",
      "Epoch 7, Loss: 709485.6755\n",
      "Epoch 8, Loss: 692245.3581\n",
      "Epoch 9, Loss: 679561.2578\n",
      "Epoch 10, Loss: 663387.7985\n",
      "Epoch 11, Loss: 643700.2670\n",
      "Epoch 12, Loss: 625698.2033\n",
      "Epoch 13, Loss: 614728.5343\n",
      "Epoch 14, Loss: 589871.0330\n",
      "Epoch 15, Loss: 572128.2108\n",
      "Epoch 16, Loss: 562436.8250\n",
      "Epoch 17, Loss: 550468.7705\n",
      "Epoch 18, Loss: 530122.7171\n",
      "Epoch 19, Loss: 514406.4097\n",
      "Epoch 20, Loss: 506651.8913\n",
      "Epoch 21, Loss: 478362.5695\n",
      "Epoch 22, Loss: 477702.8888\n",
      "Epoch 23, Loss: 453277.0479\n",
      "Epoch 24, Loss: 457292.1284\n",
      "Epoch 25, Loss: 438992.2032\n",
      "Epoch 26, Loss: 435118.6607\n",
      "Epoch 27, Loss: 421741.4523\n",
      "Epoch 28, Loss: 418006.8311\n",
      "Epoch 29, Loss: 406094.1141\n",
      "Epoch 30, Loss: 400271.3248\n",
      "Epoch 31, Loss: 398390.8109\n",
      "Epoch 32, Loss: 385688.5066\n",
      "Epoch 33, Loss: 377239.1786\n",
      "Epoch 34, Loss: 370701.5707\n",
      "Epoch 35, Loss: 358588.6721\n",
      "Epoch 36, Loss: 362448.3659\n",
      "Epoch 37, Loss: 347815.8890\n",
      "Epoch 38, Loss: 345357.5633\n",
      "Epoch 39, Loss: 337367.9434\n",
      "Epoch 40, Loss: 332809.2641\n",
      "Epoch 41, Loss: 332205.5306\n",
      "Epoch 42, Loss: 326643.2428\n",
      "Epoch 43, Loss: 318595.7872\n",
      "Epoch 44, Loss: 314442.6503\n",
      "Epoch 45, Loss: 308036.3752\n",
      "Epoch 46, Loss: 303112.6075\n",
      "Epoch 47, Loss: 299426.5621\n",
      "Epoch 48, Loss: 300573.6028\n",
      "Epoch 49, Loss: 289401.1829\n",
      "Epoch 50, Loss: 292507.5937\n",
      "Epoch 51, Loss: 283112.0886\n",
      "Epoch 52, Loss: 285574.1542\n",
      "Epoch 53, Loss: 281582.0607\n",
      "Epoch 54, Loss: 273325.7595\n",
      "Epoch 55, Loss: 277114.0968\n",
      "Epoch 56, Loss: 267873.7948\n",
      "Epoch 57, Loss: 262775.2583\n",
      "Epoch 58, Loss: 264134.3279\n",
      "Epoch 59, Loss: 264311.1810\n",
      "Epoch 60, Loss: 255700.4686\n",
      "Epoch 61, Loss: 252504.8165\n",
      "Epoch 62, Loss: 255574.4914\n",
      "Epoch 63, Loss: 251629.1108\n",
      "Epoch 64, Loss: 248581.9203\n",
      "Epoch 65, Loss: 242807.9841\n",
      "Epoch 66, Loss: 245266.7446\n",
      "Epoch 67, Loss: 236027.0209\n",
      "Epoch 68, Loss: 236490.3310\n",
      "Epoch 69, Loss: 234978.7612\n",
      "Epoch 70, Loss: 234670.9757\n",
      "Epoch 71, Loss: 227742.1870\n",
      "Epoch 72, Loss: 229205.8317\n",
      "Epoch 73, Loss: 223265.9567\n",
      "Epoch 74, Loss: 221279.3180\n",
      "Epoch 75, Loss: 218396.5878\n",
      "Epoch 76, Loss: 209062.9707\n",
      "Epoch 77, Loss: 217855.3366\n",
      "Epoch 78, Loss: 213603.1948\n",
      "Epoch 79, Loss: 207231.1487\n",
      "Epoch 80, Loss: 208020.5056\n",
      "Epoch 81, Loss: 206576.8451\n",
      "Epoch 82, Loss: 203193.2126\n",
      "Epoch 83, Loss: 196160.8831\n",
      "Epoch 84, Loss: 200932.2853\n",
      "Epoch 85, Loss: 194550.2406\n",
      "Epoch 86, Loss: 192429.0029\n",
      "Epoch 87, Loss: 189980.8864\n",
      "Epoch 88, Loss: 191553.8951\n",
      "Epoch 89, Loss: 185979.2082\n",
      "Epoch 90, Loss: 186722.8445\n",
      "Epoch 91, Loss: 186896.8476\n",
      "Epoch 92, Loss: 183058.5863\n",
      "Epoch 93, Loss: 183459.1832\n",
      "Epoch 94, Loss: 179144.9719\n",
      "Epoch 95, Loss: 178865.0684\n",
      "Epoch 96, Loss: 177581.9891\n",
      "Epoch 97, Loss: 179287.9584\n",
      "Epoch 98, Loss: 169547.3829\n",
      "Epoch 99, Loss: 174769.9012\n",
      "Epoch 100, Loss: 169546.3162\n"
     ]
    }
   ],
   "source": [
    "model = ChessEvaluationNeuralNetwork(input_size=X.shape[1])\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test RMSE: 731.1052\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "rmse_error = np.sqrt(avg_test_loss)\n",
    "print(f\"\\nTest RMSE: {rmse_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'neural_network.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
